{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0GfMDGUZCZBS"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import re\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TextPreprocessor:\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        Initialize text preprocessing utilities\n",
        "        \"\"\"\n",
        "        # Custom stopwords (you can expand this list)\n",
        "        self.stopwords = set(['the', 'a', 'an', 'in', 'to', 'for', 'of', 'and', 'is', 'are'])\n",
        "\n",
        "    def clean_text(self, text):\n",
        "        \"\"\"\n",
        "        Clean and normalize text\n",
        "        \"\"\"\n",
        "        # Convert to lowercase\n",
        "        text = text.lower()\n",
        "\n",
        "        # Remove special characters and digits\n",
        "        text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "\n",
        "        # Remove extra whitespaces\n",
        "        text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "        return text\n",
        "\n",
        "    def remove_stopwords(self, text):\n",
        "        \"\"\"\n",
        "        Remove stopwords from text\n",
        "        \"\"\"\n",
        "        return ' '.join([word for word in text.split()\n",
        "                         if word not in self.stopwords])"
      ],
      "metadata": {
        "id": "TTAeRbgpJ3nw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class KnowledgeBaseVectorizer:\n",
        "    def __init__(self, vectorization_method='tfidf'):\n",
        "        \"\"\"\n",
        "        Initialize vector representation of knowledge base\n",
        "\n",
        "        :param vectorization_method: Choice of vectorization (tfidf, word2vec)\n",
        "        \"\"\"\n",
        "        self.preprocessor = TextPreprocessor()\n",
        "        self.vectorization_method = vectorization_method\n",
        "\n",
        "        # Vectorizer will be set based on method\n",
        "        self.vectorizer = None\n",
        "        self.vectors = None\n",
        "\n",
        "    def prepare_documents(self, documents):\n",
        "        \"\"\"\n",
        "        Preprocess and clean documents\n",
        "\n",
        "        :param documents: List of raw text documents\n",
        "        :return: List of cleaned documents\n",
        "        \"\"\"\n",
        "        cleaned_docs = []\n",
        "        for doc in documents:\n",
        "            # Clean text\n",
        "            cleaned_text = self.preprocessor.clean_text(doc)\n",
        "            # Remove stopwords\n",
        "            cleaned_text = self.preprocessor.remove_stopwords(cleaned_text)\n",
        "            cleaned_docs.append(cleaned_text)\n",
        "\n",
        "        return cleaned_docs\n",
        "\n",
        "    def vectorize(self, documents):\n",
        "        \"\"\"\n",
        "        Convert documents to vector representations\n",
        "\n",
        "        :param documents: List of preprocessed documents\n",
        "        :return: Vector representations\n",
        "        \"\"\"\n",
        "        # Prepare documents\n",
        "        prepared_docs = self.prepare_documents(documents)\n",
        "\n",
        "        # Choose vectorization method\n",
        "        if self.vectorization_method == 'tfidf':\n",
        "            self.vectorizer = TfidfVectorizer()\n",
        "            self.vectors = self.vectorizer.fit_transform(prepared_docs)\n",
        "\n",
        "        return self.vectors\n",
        "\n",
        "    def compute_similarity(self, query):\n",
        "        \"\"\"\n",
        "        Compute similarity between query and knowledge base\n",
        "\n",
        "        :param query: User's query text\n",
        "        :return: Similarity scores\n",
        "        \"\"\"\n",
        "        # Preprocess query\n",
        "        cleaned_query = self.preprocessor.clean_text(query)\n",
        "        cleaned_query = self.preprocessor.remove_stopwords(cleaned_query)\n",
        "\n",
        "        # Vectorize query\n",
        "        query_vector = self.vectorizer.transform([cleaned_query])\n",
        "\n",
        "        # Compute cosine similarity\n",
        "        similarities = cosine_similarity(query_vector, self.vectors)\n",
        "\n",
        "        return similarities[0]"
      ],
      "metadata": {
        "id": "s_WEOZKBKLpe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimilarityMatcher:\n",
        "    def __init__(self, knowledge_base_documents):\n",
        "        \"\"\"\n",
        "        Initialize similarity matching system\n",
        "\n",
        "        :param knowledge_base_documents: List of documents from PDF\n",
        "        \"\"\"\n",
        "        self.vectorizer = KnowledgeBaseVectorizer()\n",
        "        self.knowledge_base_vectors = self.vectorizer.vectorize(knowledge_base_documents)\n",
        "\n",
        "    def find_most_similar(self, user_query, top_k=3):\n",
        "        \"\"\"\n",
        "        Find most similar documents to user query\n",
        "\n",
        "        :param user_query: User's input text\n",
        "        :param top_k: Number of top similar documents to return\n",
        "        :return: Top similar documents and their similarity scores\n",
        "        \"\"\"\n",
        "        # Compute similarities\n",
        "        similarities = self.vectorizer.compute_similarity(user_query)\n",
        "\n",
        "        # Get top k similar documents\n",
        "        top_indices = similarities.argsort()[-top_k:][::-1]\n",
        "        top_similarities = similarities[top_indices]\n",
        "\n",
        "        return top_indices, top_similarities\n"
      ],
      "metadata": {
        "id": "oZvSktFqKP1t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example Usage\n",
        "def main():\n",
        "    # Sample PDF extracted documents\n",
        "    pdf_documents = [\n",
        "        \"Machine learning is a subset of artificial intelligence\",\n",
        "        \"Neural networks are computational models inspired by biological neural networks\",\n",
        "        \"Deep learning involves multiple layers of neural networks\"\n",
        "    ]\n",
        "\n",
        "    # Initialize system\n",
        "    matcher = SimilarityMatcher(pdf_documents)\n",
        "\n",
        "    # Example query\n",
        "    # user_query = \"Tell me about neural networks\"\n",
        "\n",
        "    #Tes 1\n",
        "    user_query = \"Apa itu neural network\"\n",
        "\n",
        "    # Find similar documents\n",
        "    similar_indices, similarity_scores = matcher.find_most_similar(user_query)\n",
        "\n",
        "    # Print results\n",
        "    for idx, score in zip(similar_indices, similarity_scores):\n",
        "        print(f\"Document: {pdf_documents[idx]}\")\n",
        "        print(f\"Similarity Score: {score}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zT0nXgWzKShn",
        "outputId": "d8bd6246-cd68-4237-d700-ce8dabac94cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Document: Neural networks are computational models inspired by biological neural networks\n",
            "Similarity Score: 0.49022339633833373\n",
            "Document: Deep learning involves multiple layers of neural networks\n",
            "Similarity Score: 0.3175701804283441\n",
            "Document: Machine learning is a subset of artificial intelligence\n",
            "Similarity Score: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ydlbRtXzK1Ht"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}