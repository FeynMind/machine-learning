{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from transformers import AutoTokenizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score\n",
    "import re\n",
    "import fitz\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Available: False\n",
      "TensorFlow GPU: []\n"
     ]
    }
   ],
   "source": [
    "print(\"GPU Available:\", torch.cuda.is_available())\n",
    "print(\"TensorFlow GPU:\", tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "os.environ['SPACY_DATA'] = r'C:\\Users\\Salsa\\PycharmProjects\\pytorch\\.venv\\share\\spacy_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextProcessorWithPyMuPDF:\n",
    "    def __init__(self):\n",
    "        self.model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
    "        self.transformer = SentenceTransformer(self.model_name)\n",
    "    \n",
    "    def extract_from_pdf(self, pdf_path):\n",
    "        text = \"\"\n",
    "        with fitz.open(pdf_path) as doc:\n",
    "            for page in doc:\n",
    "                text += page.get_text() + \"\\n\"\n",
    "        return text\n",
    "\n",
    "    def clean_text(self, text):\n",
    "        text = re.sub(r'\\s+', ' ', text)  # Remove excessive whitespace\n",
    "        text = re.sub(r'\\n+', '\\n', text)\n",
    "        text = re.sub(r'[^\\w\\s.,:]', '', text)\n",
    "        text = re.sub(r'[^\\w\\s\\-\\'àáâãäåèéêëìíîïòóôõöùúûüýÿÀÁÂÃÄÅÈÉÊËÌÍÎÏÒÓÔÕÖÙÚÛÜÝ]', '', text)\n",
    "        return text.strip()\n",
    "    \n",
    "    def hapus_duplikat(self, text: str) -> str:\n",
    "        seen = set()\n",
    "        result_text = []\n",
    "        lines = text.split(\"\\n\")\n",
    "        for line in lines:\n",
    "            cleaned_line = line.strip()\n",
    "            if cleaned_line and cleaned_line not in seen:\n",
    "                seen.add(cleaned_line)\n",
    "                result_text.append(cleaned_line)\n",
    "        return \"\\n\".join(result_text)\n",
    "    \n",
    "    def cut_isi(self, text: str) -> str:\n",
    "        pola_2dapus = re.compile(r'(?<=daftar pustaka)(.*?)(?=daftar pustaka)', re.IGNORECASE)\n",
    "        match = pola_2dapus.search(text)\n",
    "        if match:\n",
    "            hasil = match.group(1)\n",
    "            return hasil\n",
    "        else:\n",
    "            pola_1dapus = re.compile(r'(.*?)(daftar pustaka)', re.IGNORECASE)\n",
    "            cek_1dapus = pola_1dapus.search(text)\n",
    "            if cek_1dapus:\n",
    "                hasil = cek_1dapus.group(1)\n",
    "                return hasil\n",
    "            else:\n",
    "                return \"Tidak ditemukan kata 'daftar pustaka' sama sekali.\"\n",
    "\n",
    "    def cut_daftar(self, text: str) -> str:\n",
    "        pola_titik = re.compile(r'\\.{10,}', re.DOTALL)\n",
    "        matches = list(pola_titik.finditer(text))\n",
    "        if matches:\n",
    "            last_match = matches[-1]\n",
    "            last_match_end = last_match.end()\n",
    "            text = text[last_match_end:].strip()\n",
    "        return text\n",
    "\n",
    "    def segment_text(self, text, max_length=512):\n",
    "        segments = re.split(r'(?<=[.!?])\\s+', text)\n",
    "        processed_segments, current_segment = [], \"\"\n",
    "        for segment in segments:\n",
    "            if len(current_segment) + len(segment) < max_length:\n",
    "                current_segment += \" \" + segment if current_segment else segment\n",
    "            else:\n",
    "                processed_segments.append(current_segment)\n",
    "                current_segment = segment\n",
    "        if current_segment:\n",
    "            processed_segments.append(current_segment)\n",
    "        return processed_segments\n",
    "    \n",
    "    def generate_embeddings(self, texts):\n",
    "        return self.transformer.encode(texts, convert_to_tensor=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total segments processed: 66\n"
     ]
    }
   ],
   "source": [
    "pdf_dir = \"Perkategori/\"  # Directory containing PDF files\n",
    "processor = TextProcessorWithPyMuPDF()\n",
    "\n",
    "all_segments = []\n",
    "for pdf_file in os.listdir(pdf_dir):\n",
    "    if pdf_file.endswith(\".pdf\"):\n",
    "        pdf_path = os.path.join(pdf_dir, pdf_file)\n",
    "        raw_text = processor.extract_from_pdf(pdf_path)\n",
    "        cleaned_text = processor.clean_text(raw_text)\n",
    "        cleaned_text = processor.hapus_duplikat(cleaned_text)\n",
    "        cleaned_text = processor.cut_isi(cleaned_text)\n",
    "        cleaned_text = processor.cut_daftar(cleaned_text)\n",
    "        segments = processor.segment_text(cleaned_text)\n",
    "        all_segments.extend(segments)  # This will append all the segments to the list\n",
    "\n",
    "print(f\"Total segments processed: {len(all_segments)}\")\n",
    "\n",
    "# Generate Embeddings\n",
    "embeddings = processor.generate_embeddings(all_segments)\n",
    "embeddings_np = embeddings.cpu().numpy() if torch.cuda.is_available() else embeddings.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "half_dim = embeddings_np.shape[1] // 2\n",
    "text_data = embeddings_np[:, :half_dim]\n",
    "explanation_data = embeddings_np[:, half_dim:]\n",
    "\n",
    "input_data = {\n",
    "    \"text_input\": text_data,\n",
    "    \"explanation_input\": explanation_data\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulated Labels\n",
    "num_samples = embeddings_np.shape[0]\n",
    "understanding_labels = np.random.randint(0, 3, (num_samples, 3))  # One-hot encoded\n",
    "completeness_labels = np.random.randint(0, 2, (num_samples,))    # Binary\n",
    "\n",
    "output_data = {\n",
    "    \"understanding\": understanding_labels,\n",
    "    \"completeness\": completeness_labels\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " text_input (InputLayer)     [(None, 192)]                0         []                            \n",
      "                                                                                                  \n",
      " explanation_input (InputLa  [(None, 192)]                0         []                            \n",
      " yer)                                                                                             \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate  (None, 384)                  0         ['text_input[0][0]',          \n",
      " )                                                                   'explanation_input[0][0]']   \n",
      "                                                                                                  \n",
      " dense_8 (Dense)             (None, 512)                  197120    ['concatenate_4[0][0]']       \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)         (None, 512)                  0         ['dense_8[0][0]']             \n",
      "                                                                                                  \n",
      " dense_9 (Dense)             (None, 256)                  131328    ['dropout_8[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_9 (Dropout)         (None, 256)                  0         ['dense_9[0][0]']             \n",
      "                                                                                                  \n",
      " understanding (Dense)       (None, 3)                    771       ['dropout_9[0][0]']           \n",
      "                                                                                                  \n",
      " completeness (Dense)        (None, 1)                    257       ['dropout_9[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 329476 (1.26 MB)\n",
      "Trainable params: 329476 (1.26 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_tf_model(embedding_dim=384):\n",
    "    text_input = tf.keras.layers.Input(shape=(embedding_dim // 2,), name='text_input')\n",
    "    explanation_input = tf.keras.layers.Input(shape=(embedding_dim // 2,), name='explanation_input')\n",
    "    concatenated = tf.keras.layers.Concatenate()([text_input, explanation_input])\n",
    "    \n",
    "    x = tf.keras.layers.Dense(512, activation='relu')(concatenated)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "    x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "    \n",
    "    understanding_score = tf.keras.layers.Dense(3, activation='softmax', name='understanding')(x)\n",
    "    completeness_score = tf.keras.layers.Dense(1, activation='sigmoid', name='completeness')(x)\n",
    "    \n",
    "    model = tf.keras.Model(\n",
    "        inputs=[text_input, explanation_input],\n",
    "        outputs=[understanding_score, completeness_score]\n",
    "    )\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss={\n",
    "            'understanding': 'categorical_crossentropy',\n",
    "            'completeness': 'binary_crossentropy'\n",
    "        },\n",
    "        metrics={\n",
    "            'understanding': 'accuracy',\n",
    "            'completeness': 'accuracy'\n",
    "        }\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# Initialize Model\n",
    "tf_model = create_tf_model()\n",
    "tf_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2/2 [==============================] - 2s 345ms/step - loss: 3.7078 - understanding_loss: 3.0130 - completeness_loss: 0.6948 - understanding_accuracy: 0.3269 - completeness_accuracy: 0.4423 - val_loss: 4.6419 - val_understanding_loss: 3.9491 - val_completeness_loss: 0.6928 - val_understanding_accuracy: 0.2857 - val_completeness_accuracy: 0.4286\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 3.6521 - understanding_loss: 2.9652 - completeness_loss: 0.6869 - understanding_accuracy: 0.3654 - completeness_accuracy: 0.5769 - val_loss: 4.6665 - val_understanding_loss: 3.9790 - val_completeness_loss: 0.6875 - val_understanding_accuracy: 0.2857 - val_completeness_accuracy: 0.6429\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 3.6245 - understanding_loss: 2.9497 - completeness_loss: 0.6748 - understanding_accuracy: 0.4038 - completeness_accuracy: 0.5962 - val_loss: 4.7171 - val_understanding_loss: 4.0358 - val_completeness_loss: 0.6813 - val_understanding_accuracy: 0.2857 - val_completeness_accuracy: 0.6429\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 3.5972 - understanding_loss: 2.9105 - completeness_loss: 0.6867 - understanding_accuracy: 0.4038 - completeness_accuracy: 0.5000 - val_loss: 4.8085 - val_understanding_loss: 4.1299 - val_completeness_loss: 0.6785 - val_understanding_accuracy: 0.2857 - val_completeness_accuracy: 0.6429\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 3.6566 - understanding_loss: 2.9705 - completeness_loss: 0.6861 - understanding_accuracy: 0.4038 - completeness_accuracy: 0.4808 - val_loss: 4.9535 - val_understanding_loss: 4.2765 - val_completeness_loss: 0.6771 - val_understanding_accuracy: 0.2857 - val_completeness_accuracy: 0.6429\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 3.6142 - understanding_loss: 2.9359 - completeness_loss: 0.6784 - understanding_accuracy: 0.4038 - completeness_accuracy: 0.5769 - val_loss: 5.1327 - val_understanding_loss: 4.4566 - val_completeness_loss: 0.6761 - val_understanding_accuracy: 0.2857 - val_completeness_accuracy: 0.6429\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 3.7970 - understanding_loss: 3.0960 - completeness_loss: 0.7010 - understanding_accuracy: 0.4038 - completeness_accuracy: 0.5192 - val_loss: 5.3660 - val_understanding_loss: 4.6900 - val_completeness_loss: 0.6761 - val_understanding_accuracy: 0.2857 - val_completeness_accuracy: 0.6429\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 3.8284 - understanding_loss: 3.1352 - completeness_loss: 0.6932 - understanding_accuracy: 0.3846 - completeness_accuracy: 0.5769 - val_loss: 5.5988 - val_understanding_loss: 4.9242 - val_completeness_loss: 0.6746 - val_understanding_accuracy: 0.2857 - val_completeness_accuracy: 0.6429\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 4.0062 - understanding_loss: 3.3173 - completeness_loss: 0.6889 - understanding_accuracy: 0.4038 - completeness_accuracy: 0.5962 - val_loss: 5.8221 - val_understanding_loss: 5.1478 - val_completeness_loss: 0.6743 - val_understanding_accuracy: 0.2857 - val_completeness_accuracy: 0.6429\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 4.0924 - understanding_loss: 3.4328 - completeness_loss: 0.6595 - understanding_accuracy: 0.3846 - completeness_accuracy: 0.6154 - val_loss: 6.0242 - val_understanding_loss: 5.3499 - val_completeness_loss: 0.6743 - val_understanding_accuracy: 0.2857 - val_completeness_accuracy: 0.6429\n"
     ]
    }
   ],
   "source": [
    "history = tf_model.fit(\n",
    "    input_data,\n",
    "    output_data,\n",
    "    validation_split=0.2,\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2/2 [==============================] - 0s 154ms/step - loss: 4.7677 - understanding_loss: 4.0189 - completeness_loss: 0.7487 - understanding_accuracy: 0.3077 - completeness_accuracy: 0.5577 - val_loss: 4.4222 - val_understanding_loss: 3.6974 - val_completeness_loss: 0.7248 - val_understanding_accuracy: 0.5000 - val_completeness_accuracy: 0.5000\n",
      "Epoch 2/5\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 5.0102 - understanding_loss: 4.2459 - completeness_loss: 0.7643 - understanding_accuracy: 0.3269 - completeness_accuracy: 0.5385 - val_loss: 4.5097 - val_understanding_loss: 3.7811 - val_completeness_loss: 0.7286 - val_understanding_accuracy: 0.5000 - val_completeness_accuracy: 0.5000\n",
      "Epoch 3/5\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 5.0723 - understanding_loss: 4.3363 - completeness_loss: 0.7360 - understanding_accuracy: 0.2692 - completeness_accuracy: 0.5962 - val_loss: 4.5926 - val_understanding_loss: 3.8577 - val_completeness_loss: 0.7349 - val_understanding_accuracy: 0.5000 - val_completeness_accuracy: 0.5000\n",
      "Epoch 4/5\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 5.4767 - understanding_loss: 4.6782 - completeness_loss: 0.7986 - understanding_accuracy: 0.3077 - completeness_accuracy: 0.5000 - val_loss: 4.7158 - val_understanding_loss: 3.9801 - val_completeness_loss: 0.7357 - val_understanding_accuracy: 0.5000 - val_completeness_accuracy: 0.5000\n",
      "Epoch 5/5\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 5.5711 - understanding_loss: 4.7422 - completeness_loss: 0.8288 - understanding_accuracy: 0.3462 - completeness_accuracy: 0.4423 - val_loss: 4.8520 - val_understanding_loss: 4.1166 - val_completeness_loss: 0.7354 - val_understanding_accuracy: 0.5000 - val_completeness_accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "Fold complete.\n",
      "Epoch 1/5\n",
      "2/2 [==============================] - 0s 121ms/step - loss: 6.2522 - understanding_loss: 5.4891 - completeness_loss: 0.7631 - understanding_accuracy: 0.2642 - completeness_accuracy: 0.5660 - val_loss: 4.6283 - val_understanding_loss: 3.9351 - val_completeness_loss: 0.6932 - val_understanding_accuracy: 0.2308 - val_completeness_accuracy: 0.5385\n",
      "Epoch 2/5\n",
      "2/2 [==============================] - 0s 126ms/step - loss: 6.1981 - understanding_loss: 5.2103 - completeness_loss: 0.9878 - understanding_accuracy: 0.3396 - completeness_accuracy: 0.5472 - val_loss: 4.6794 - val_understanding_loss: 3.9831 - val_completeness_loss: 0.6963 - val_understanding_accuracy: 0.0769 - val_completeness_accuracy: 0.5385\n",
      "Epoch 3/5\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 5.8213 - understanding_loss: 4.9138 - completeness_loss: 0.9075 - understanding_accuracy: 0.3208 - completeness_accuracy: 0.6038 - val_loss: 4.8063 - val_understanding_loss: 4.0871 - val_completeness_loss: 0.7191 - val_understanding_accuracy: 0.0769 - val_completeness_accuracy: 0.5385\n",
      "Epoch 4/5\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 7.1352 - understanding_loss: 5.9834 - completeness_loss: 1.1518 - understanding_accuracy: 0.2453 - completeness_accuracy: 0.6038 - val_loss: 4.9143 - val_understanding_loss: 4.1935 - val_completeness_loss: 0.7208 - val_understanding_accuracy: 0.0769 - val_completeness_accuracy: 0.5385\n",
      "Epoch 5/5\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 7.0870 - understanding_loss: 5.8141 - completeness_loss: 1.2729 - understanding_accuracy: 0.2830 - completeness_accuracy: 0.4340 - val_loss: 5.0325 - val_understanding_loss: 4.3075 - val_completeness_loss: 0.7250 - val_understanding_accuracy: 0.0769 - val_completeness_accuracy: 0.5385\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Fold complete.\n",
      "Epoch 1/5\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 9.0542 - understanding_loss: 7.9036 - completeness_loss: 1.1506 - understanding_accuracy: 0.4151 - completeness_accuracy: 0.4717 - val_loss: 4.7724 - val_understanding_loss: 4.0737 - val_completeness_loss: 0.6987 - val_understanding_accuracy: 0.2308 - val_completeness_accuracy: 0.3077\n",
      "Epoch 2/5\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 10.6352 - understanding_loss: 9.1984 - completeness_loss: 1.4368 - understanding_accuracy: 0.3396 - completeness_accuracy: 0.4717 - val_loss: 5.0495 - val_understanding_loss: 4.1455 - val_completeness_loss: 0.9041 - val_understanding_accuracy: 0.2308 - val_completeness_accuracy: 0.3077\n",
      "Epoch 3/5\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 11.6339 - understanding_loss: 9.7893 - completeness_loss: 1.8445 - understanding_accuracy: 0.2453 - completeness_accuracy: 0.3962 - val_loss: 5.3798 - val_understanding_loss: 4.2012 - val_completeness_loss: 1.1786 - val_understanding_accuracy: 0.2308 - val_completeness_accuracy: 0.1538\n",
      "Epoch 4/5\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 11.9385 - understanding_loss: 9.8189 - completeness_loss: 2.1196 - understanding_accuracy: 0.3585 - completeness_accuracy: 0.4151 - val_loss: 5.2856 - val_understanding_loss: 4.2294 - val_completeness_loss: 1.0562 - val_understanding_accuracy: 0.2308 - val_completeness_accuracy: 0.1538\n",
      "Epoch 5/5\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 12.1326 - understanding_loss: 10.7647 - completeness_loss: 1.3679 - understanding_accuracy: 0.2453 - completeness_accuracy: 0.5472 - val_loss: 5.0352 - val_understanding_loss: 4.1657 - val_completeness_loss: 0.8695 - val_understanding_accuracy: 0.2308 - val_completeness_accuracy: 0.3846\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "Fold complete.\n",
      "Epoch 1/5\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 17.2537 - understanding_loss: 14.9441 - completeness_loss: 2.3096 - understanding_accuracy: 0.2453 - completeness_accuracy: 0.4717 - val_loss: 5.3230 - val_understanding_loss: 4.5834 - val_completeness_loss: 0.7396 - val_understanding_accuracy: 0.1538 - val_completeness_accuracy: 0.6154\n",
      "Epoch 2/5\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 15.3122 - understanding_loss: 13.2157 - completeness_loss: 2.0964 - understanding_accuracy: 0.3585 - completeness_accuracy: 0.5849 - val_loss: 5.6578 - val_understanding_loss: 4.7556 - val_completeness_loss: 0.9023 - val_understanding_accuracy: 0.1538 - val_completeness_accuracy: 0.6154\n",
      "Epoch 3/5\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 19.3379 - understanding_loss: 16.7225 - completeness_loss: 2.6154 - understanding_accuracy: 0.3208 - completeness_accuracy: 0.4906 - val_loss: 6.0366 - val_understanding_loss: 4.9474 - val_completeness_loss: 1.0892 - val_understanding_accuracy: 0.1538 - val_completeness_accuracy: 0.6154\n",
      "Epoch 4/5\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 18.8168 - understanding_loss: 16.2850 - completeness_loss: 2.5318 - understanding_accuracy: 0.3019 - completeness_accuracy: 0.5283 - val_loss: 6.5029 - val_understanding_loss: 5.3823 - val_completeness_loss: 1.1205 - val_understanding_accuracy: 0.1538 - val_completeness_accuracy: 0.6154\n",
      "Epoch 5/5\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 23.3765 - understanding_loss: 20.6470 - completeness_loss: 2.7295 - understanding_accuracy: 0.2830 - completeness_accuracy: 0.5660 - val_loss: 6.5111 - val_understanding_loss: 5.8555 - val_completeness_loss: 0.6556 - val_understanding_accuracy: 0.1538 - val_completeness_accuracy: 0.5385\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "Fold complete.\n",
      "Epoch 1/5\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 23.8521 - understanding_loss: 21.0038 - completeness_loss: 2.8482 - understanding_accuracy: 0.3208 - completeness_accuracy: 0.5660 - val_loss: 7.3454 - val_understanding_loss: 6.6879 - val_completeness_loss: 0.6574 - val_understanding_accuracy: 0.0000e+00 - val_completeness_accuracy: 0.6923\n",
      "Epoch 2/5\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 26.4507 - understanding_loss: 21.3138 - completeness_loss: 5.1369 - understanding_accuracy: 0.3774 - completeness_accuracy: 0.4151 - val_loss: 7.5969 - val_understanding_loss: 7.0758 - val_completeness_loss: 0.5211 - val_understanding_accuracy: 0.0000e+00 - val_completeness_accuracy: 0.6923\n",
      "Epoch 3/5\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 27.5491 - understanding_loss: 23.5396 - completeness_loss: 4.0095 - understanding_accuracy: 0.3585 - completeness_accuracy: 0.4906 - val_loss: 8.9383 - val_understanding_loss: 7.0259 - val_completeness_loss: 1.9124 - val_understanding_accuracy: 0.0000e+00 - val_completeness_accuracy: 0.3077\n",
      "Epoch 4/5\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 27.7126 - understanding_loss: 24.3511 - completeness_loss: 3.3616 - understanding_accuracy: 0.4151 - completeness_accuracy: 0.5849 - val_loss: 11.0611 - val_understanding_loss: 7.5369 - val_completeness_loss: 3.5242 - val_understanding_accuracy: 0.0000e+00 - val_completeness_accuracy: 0.3077\n",
      "Epoch 5/5\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 37.0010 - understanding_loss: 32.4917 - completeness_loss: 4.5093 - understanding_accuracy: 0.3396 - completeness_accuracy: 0.5849 - val_loss: 12.3794 - val_understanding_loss: 8.5569 - val_completeness_loss: 3.8225 - val_understanding_accuracy: 0.0000e+00 - val_completeness_accuracy: 0.3077\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Fold complete.\n"
     ]
    }
   ],
   "source": [
    "# Cross-Validation\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "fold_results = []\n",
    "\n",
    "for train_idx, val_idx in kfold.split(text_data):\n",
    "    X_train = {\"text_input\": text_data[train_idx], \"explanation_input\": explanation_data[train_idx]}\n",
    "    X_val = {\"text_input\": text_data[val_idx], \"explanation_input\": explanation_data[val_idx]}\n",
    "    \n",
    "    y_train = {\n",
    "        \"understanding\": understanding_labels[train_idx],\n",
    "        \"completeness\": completeness_labels[train_idx]\n",
    "    }\n",
    "    y_val = {\n",
    "        \"understanding\": understanding_labels[val_idx],\n",
    "        \"completeness\": completeness_labels[val_idx]\n",
    "    }\n",
    "    \n",
    "    tf_model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=5, batch_size=32, verbose=1)\n",
    "    predictions = tf_model.predict(X_val)\n",
    "    understanding_pred = predictions[0].argmax(axis=-1)\n",
    "    completeness_pred = (predictions[1] > 0.5).astype(int)\n",
    "    print(\"Fold complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf_model.save(\"feynmind_model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
